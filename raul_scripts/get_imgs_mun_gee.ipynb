{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe075955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google_auth_oauthlib in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: google-auth<2.42.0,>=2.15.0 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google_auth_oauthlib) (2.40.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google_auth_oauthlib) (2.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth<2.42.0,>=2.15.0->google_auth_oauthlib) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth<2.42.0,>=2.15.0->google_auth_oauthlib) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth<2.42.0,>=2.15.0->google_auth_oauthlib) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<2.42.0,>=2.15.0->google_auth_oauthlib) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests-oauthlib>=0.7.0->google_auth_oauthlib) (3.3.1)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests-oauthlib>=0.7.0->google_auth_oauthlib) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google_auth_oauthlib) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google_auth_oauthlib) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google_auth_oauthlib) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\heigt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google_auth_oauthlib) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google_auth_oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ebfb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import os\n",
    "import io\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import time \n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class manager_img_gee():\n",
    "    def __init__(self, project):\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize(project=project)\n",
    "        self.drive_service = self._authenticate()\n",
    "        self.folder_id = None\n",
    "        self.folder_name = None\n",
    "        self.target_folder_id = None\n",
    "        self.target_folder_name = None\n",
    "    \n",
    "    def _log_message(self, message):\n",
    "        dt_new = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{dt_new}] - {message}\")\n",
    "\n",
    "    def _log_error(self, error):\n",
    "        dt_new = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        raise RuntimeError(f\"[{dt_new}] - Erro: {error}\")\n",
    "\n",
    "    def _authenticate(self):\n",
    "        SCOPES = [\"https://www.googleapis.com/auth/drive\"] \n",
    "\n",
    "        creds = None\n",
    "        if os.path.exists(\"data/token.json\"):\n",
    "            creds = Credentials.from_authorized_user_file(\"data/token.json\", SCOPES)\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\"data/credentials.json\", SCOPES)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            with open(\"data/token.json\", \"w\") as token:\n",
    "                token.write(creds.to_json())\n",
    "        \n",
    "        return build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "    def _get_folder_id_by_name(self, folder_name):\n",
    "        \"\"\"\n",
    "        Obtém o ID de uma pasta no Google Drive pelo nome.\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): O nome da pasta a ser pesquisada.\n",
    "\n",
    "        Returns:\n",
    "            str | None: O ID da pasta se encontrada, caso contrário None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            query = f\"name = '{folder_name}' and mimeType = 'application/vnd.google-apps.folder' and 'root' in parents\"\n",
    "            response = self.drive_service.files().list(q=query, pageSize=1, fields=\"files(id, name)\").execute()\n",
    "            items = response.get('files', [])\n",
    "            if not items:\n",
    "                self._log_message(f\"Pasta '{folder_name}' não encontrada no Google Drive. Ela será criada se necessário.\")\n",
    "                return None\n",
    "            return items[0].get('id')\n",
    "        except HttpError as error:\n",
    "            self._log_error(f\"Ocorreu um erro na API do Drive ao buscar a pasta: {error}\")\n",
    "\n",
    "    def get_active_gee_task_count(self):\n",
    "        \"\"\"\n",
    "        Conta o número de tarefas de exportação ativas ('RUNNING' ou 'READY') no GEE.\n",
    "\n",
    "        Returns:\n",
    "            int: O número de tarefas ativas.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            task_list = ee.data.getTaskList()\n",
    "            active_states = {'RUNNING', 'READY'}\n",
    "            active_tasks = [task for task in task_list if task['state'] in active_states]\n",
    "            return len(active_tasks)\n",
    "        except Exception as e:\n",
    "            self._log_error(f\"Erro ao obter a lista de tarefas do Google Earth Engine: {e}\")\n",
    "\n",
    "    def _check_folder_capacity(self, folder_name, limit):\n",
    "        \"\"\"\n",
    "        Verifica se a pasta de destino no Google Drive tem capacidade para novos arquivos.\n",
    "        A capacidade é limitada a 20 itens (arquivos existentes + tarefas GEE ativas).\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): O nome da pasta no Google Drive.\n",
    "\n",
    "        Returns:\n",
    "            bool: True se a pasta tiver capacidade, False caso contrário.\n",
    "        \"\"\"\n",
    "        # Verifica se a pasta precisa ser atualizada\n",
    "        if self.target_folder_name != folder_name or self.target_folder_id is None:\n",
    "            self._log_message(f\"Verificando a pasta '{folder_name}' no Google Drive...\")\n",
    "            self.target_folder_name = folder_name\n",
    "            self.target_folder_id = self._get_folder_id_by_name(folder_name)\n",
    "            # Se a pasta não existe, ela tem capacidade para a primeira tarefa\n",
    "            if self.target_folder_id is None:\n",
    "                return True\n",
    "            self._log_message(f\"Pasta '{folder_name}' verificada com sucesso.\")\n",
    "\n",
    "        num_active_tasks = self.get_active_gee_task_count()\n",
    "\n",
    "        try:\n",
    "            # Conta os arquivos na pasta do Drive\n",
    "            response = self.drive_service.files().list(q=f\"'{self.target_folder_id}' in parents\", pageSize=21, fields=\"files(id)\").execute()\n",
    "            items = response.get('files', [])\n",
    "            total_items = len(items) + num_active_tasks\n",
    "\n",
    "            if total_items <= limit:\n",
    "                return True\n",
    "            else:\n",
    "                self._log_message(f\"A pasta '{folder_name}' contém {len(items)} arquivos e {num_active_tasks} tarefas ativas, totalizando {total_items}. Aguardando ter menos de 20 itens para continuar...\")\n",
    "                return False\n",
    "        except HttpError as error:\n",
    "            self._log_error(f\"Ocorreu um erro na API do Drive ao verificar a pasta: {error}\")\n",
    "\n",
    "    def _wait_for_folder_capacity(self, folder_name, limit):\n",
    "        \"\"\"\n",
    "        Aguarda até que a pasta de destino tenha capacidade para novos arquivos,\n",
    "        verificando a cada 10 minutos.\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): O nome da pasta no Google Drive.\n",
    "        \"\"\"\n",
    "        wait_count = 0\n",
    "        while not self._check_folder_capacity(folder_name, limit):\n",
    "            self._log_message(f\"Aguardando capacidade na pasta '{folder_name}'...\")\n",
    "            time.sleep(60 * 10)  # Espera 10 minutos\n",
    "            wait_count += 1\n",
    "            if wait_count > 6: # Timeout após ~1 hora\n",
    "                self._log_error(f\"O fluxo de arquivos na pasta '{folder_name}' demorou demais para ser liberado.\")\n",
    "\n",
    "    def _get_all_acquisition_dates(self, area_of_interest, start_date, end_date, satellite, SR=False):\n",
    "        \"\"\"\n",
    "        Obtém todas as datas de aquisição únicas para um determinado satélite e período.\n",
    "\n",
    "        Args:\n",
    "            area_of_interest (ee.Geometry): A área de interesse.\n",
    "            start_date (str): Data de início (YYYY-MM-DD).\n",
    "            end_date (str): Data de fim (YYYY-MM-DD).\n",
    "            satellite (str): 'sentinel1' ou 'sentinel2'.\n",
    "            SR (bool): Usar reflectância de superfície para Sentinel-2.\n",
    "\n",
    "        Returns:\n",
    "            list: Uma lista de datas de aquisição (YYYY-MM-DD).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            collection = None\n",
    "            if satellite == 'sentinel1':\n",
    "                collection = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "                               .filterBounds(area_of_interest) \\\n",
    "                               .filterDate(start_date, end_date) \\\n",
    "                               .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "                               .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')) \\\n",
    "                               .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "            elif satellite == 'sentinel2':\n",
    "                collection_id = 'COPERNICUS/S2_SR_HARMONIZED' if SR else 'COPERNICUS/S2_HARMONIZED'\n",
    "                collection = ee.ImageCollection(collection_id) \\\n",
    "                               .filterBounds(area_of_interest) \\\n",
    "                               .filterDate(start_date, end_date) \\\n",
    "                               .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n",
    "            else:\n",
    "                self._log_error(f\"Satélite '{satellite}' não suportado.\")\n",
    "                return []\n",
    "\n",
    "            timestamps = collection.aggregate_array('system:time_start').getInfo()\n",
    "            if not timestamps:\n",
    "                self._log_error(f\"Nenhum dado encontrado para o satélite {satellite} no período especificado.\")\n",
    "                return []\n",
    "\n",
    "            unique_dates = sorted(list(set([datetime.utcfromtimestamp(ts / 1000).strftime('%Y-%m-%d') for ts in timestamps])))\n",
    "            self._log_message(f\"Datas de aquisição encontradas para {satellite}: {unique_dates}\")\n",
    "            return unique_dates\n",
    "        except Exception as e:\n",
    "            self._log_error(f\"Erro ao obter datas de aquisição para {satellite}: {e}\")\n",
    "\n",
    "    def _start_export_task(self, image, filename, folder_name, area_of_interest, satellite):\n",
    "        \"\"\"\n",
    "        Inicia uma tarefa de exportação de imagem do GEE para o Google Drive.\n",
    "\n",
    "        Args:\n",
    "            image (ee.Image): A imagem a ser exportada.\n",
    "            filename (str): O nome do arquivo de saída.\n",
    "            folder_name (str): A pasta de destino no Google Drive.\n",
    "            area_of_interest (ee.Geometry): A área de interesse para o recorte.\n",
    "            satellite (str): 'sentinel1' ou 'sentinel2' para selecionar as bandas corretas.\n",
    "        \"\"\"\n",
    "        bands = ['VH', 'VV'] if satellite == 'sentinel1' else ['B4', 'B3', 'B2']\n",
    "        task_config = {\n",
    "            'image': image.select(bands),\n",
    "            'description': filename,\n",
    "            'folder': folder_name,\n",
    "            'fileNamePrefix': filename,\n",
    "            'scale': 10,\n",
    "            'region': area_of_interest,\n",
    "            'fileFormat': 'GeoTIFF',\n",
    "            'maxPixels': 1e12,\n",
    "        }\n",
    "        task = ee.batch.Export.image.toDrive(**task_config)\n",
    "        task.start()\n",
    "        self._log_message(f\"Tarefa de exportação iniciada: {filename}\")\n",
    "\n",
    "\n",
    "    def _get_sentinel2_cloud_masked_composite(self, area_of_interest, start_date, end_date, SR=False):\n",
    "        \"\"\"Cria um mosaico Sentinel-2 com máscara de nuvens usando o Cloud Score+.\"\"\"\n",
    "        collection_id = 'COPERNICUS/S2_SR_HARMONIZED' if SR else 'COPERNICUS/S2_HARMONIZED'\n",
    "        s2_collection = ee.ImageCollection(collection_id).filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
    "        cloud_score_collection = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED')\n",
    "        QA_BAND = 'cs'\n",
    "        CLEAR_THRESHOLD = 0.60\n",
    "\n",
    "        # Vincula a coleção do Sentinel-2 com a do Cloud Score\n",
    "        s2_with_cs = s2_collection.filterBounds(area_of_interest) \\\n",
    "                                  .filterDate(start_date, end_date) \\\n",
    "                                  .linkCollection(cloud_score_collection, [QA_BAND])\n",
    "        \n",
    "        # Função para aplicar a máscara de nuvem\n",
    "        def apply_cloud_mask(image):\n",
    "            return image.updateMask(image.select(QA_BAND).gte(CLEAR_THRESHOLD))\n",
    "\n",
    "        composite = s2_with_cs.map(apply_cloud_mask).median().clip(area_of_interest)\n",
    "        return composite\n",
    "\n",
    "    def _download_file_from_drive(self, file_id, file_name, local_path):\n",
    "        \"\"\"Baixa um arquivo do Google Drive para um diretório local.\"\"\"\n",
    "        try:\n",
    "            self._log_message(f\"Iniciando o download do arquivo '{file_name}'...\")\n",
    "            request = self.drive_service.files().get_media(fileId=file_id)\n",
    "            fh = io.BytesIO()\n",
    "            downloader = MediaIoBaseDownload(fh, request)\n",
    "            done = False\n",
    "            while not done:\n",
    "                status, done = downloader.next_chunk()\n",
    "            \n",
    "            with open(os.path.join(local_path, file_name), \"wb\") as f:\n",
    "                f.write(fh.getbuffer())\n",
    "            self._log_message(f\"Arquivo '{file_name}' baixado com sucesso.\")\n",
    "        except HttpError as error:\n",
    "            self._log_error(f\"Erro ao baixar o arquivo {file_name}: {error}\")\n",
    "\n",
    "    def _delete_file_from_drive(self, file_id, file_name):\n",
    "        \"\"\"Remove um arquivo do Google Drive.\"\"\"\n",
    "        try:\n",
    "            self.drive_service.files().delete(fileId=file_id).execute()\n",
    "            self._log_message(f\"Arquivo '{file_name}' removido do Google Drive.\")\n",
    "        except HttpError as error:\n",
    "            self._log_error(f\"Erro ao remover o arquivo '{file_name}' do Google Drive: {error}\")\n",
    "\n",
    "    def export_images_to_drive(self, area_of_interest, start_date, end_date, satellite, folder_name, base_filename, SR=False, limit=500, sentinel1_dates=None):\n",
    "        \"\"\"\n",
    "        Orquestra a exportação de imagens de satélite para o Google Drive.\n",
    "        Para Sentinel-1, exporta uma imagem por data de aquisição.\n",
    "        Para Sentinel-2, exporta um mosaico mediano sem nuvens para todo o período.\n",
    "\n",
    "        Args:\n",
    "            area_of_interest (ee.Geometry): A área de interesse do GEE.\n",
    "            start_date (str): Data de início (YYYY-MM-DD).\n",
    "            end_date (str): Data de fim (YYYY-MM-DD).\n",
    "            satellite (str): 'sentinel1' ou 'sentinel2'.\n",
    "            folder_name (str): A pasta de destino no Google Drive.\n",
    "            base_filename (str): O prefixo para os nomes dos arquivos.\n",
    "            SR (bool): Para Sentinel-2, indica se usa reflectância de superfície.\n",
    "            limit (int): Limite de capacidade da pasta.\n",
    "            sentinel1_dates (list): Lista opcional de datas específicas (formato YYYY-MM-DD) \n",
    "                                    para Sentinel-1. Se None, usa a lógica padrão de 10 datas.\n",
    "        \"\"\"\n",
    "        if satellite == 'sentinel2':\n",
    "            self._wait_for_folder_capacity(folder_name, limit)\n",
    "            s2_image = self._get_sentinel2_cloud_masked_composite(area_of_interest, start_date, end_date, SR)\n",
    "            filename = f\"{base_filename}_{satellite}_{start_date}_to_{end_date}\"\n",
    "            self._start_export_task(s2_image, filename, folder_name, area_of_interest, satellite)\n",
    "        \n",
    "        elif satellite == 'sentinel1':\n",
    "            # Se datas específicas foram fornecidas, usa elas; caso contrário, usa a lógica padrão\n",
    "            if sentinel1_dates is not None:\n",
    "                self._log_message(f\"Usando datas específicas fornecidas: {sentinel1_dates}\")\n",
    "                acquisition_dates = sentinel1_dates\n",
    "                \n",
    "            # --- NOVA VERIFICAÇÃO DE DISPONIBILIDADE ---\n",
    "            self._log_message(\"Verificando disponibilidade de imagens Sentinel-1 para todas as datas especificadas...\")\n",
    "            missing_dates = []\n",
    "            for date in acquisition_dates:\n",
    "                images = self._get_sentinel1_images(area_of_interest, date)\n",
    "                if images is None:  \n",
    "                    missing_dates.append(date)\n",
    "\n",
    "            if missing_dates:\n",
    "                self._log_message(f\"As seguintes datas não possuem imagens Sentinel-1 disponíveis: {missing_dates}.\")\n",
    "                self._log_message(\"Pulando execução deste município por falta de dados completos.\")\n",
    "                return  \n",
    "            else:\n",
    "                self._log_message(\"Todas as datas possuem imagens disponíveis. Iniciando exportação...\")\n",
    "\n",
    "            for date in acquisition_dates:\n",
    "                images = self._get_sentinel1_images(area_of_interest, date)\n",
    "                num_images = images.size().getInfo()\n",
    "\n",
    "                for i in range(num_images):\n",
    "                    self._wait_for_folder_capacity(folder_name, limit)\n",
    "                    image = ee.Image(images.get(i))\n",
    "                    filename = f\"{base_filename}_{satellite}_{date}_img{i+1:02d}\"\n",
    "                    self._start_export_task(image, filename, folder_name, area_of_interest, satellite)\n",
    "\n",
    "\n",
    "    def download_latest_file_from_drive(self, folder_name, local_path=\"downloads\"):\n",
    "        \"\"\"\n",
    "        Baixa o arquivo mais antigo da pasta especificada no Drive e o remove em seguida.\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): O nome da pasta no Google Drive.\n",
    "            local_path (str): O caminho do diretório local para salvar o arquivo.\n",
    "\n",
    "        Returns:\n",
    "            str | None: O nome do arquivo baixado ou None se a pasta estiver vazia.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            folder_id = self._get_folder_id_by_name(folder_name)\n",
    "            if not folder_id:\n",
    "                self._log_message(f\"A pasta '{folder_name}' não existe. Nenhum arquivo para baixar.\")\n",
    "                return None\n",
    "\n",
    "            if not os.path.exists(local_path):\n",
    "                os.makedirs(local_path)\n",
    "                self._log_message(f\"Diretório local '{local_path}' criado.\")\n",
    "            \n",
    "            # Busca o arquivo mais antigo (primeiro a ser criado) na pasta\n",
    "            response = self.drive_service.files().list(\n",
    "                q=f\"'{folder_id}' in parents and trashed=false\",\n",
    "                pageSize=1,\n",
    "                fields=\"files(id, name)\",\n",
    "                orderBy=\"createdTime\"\n",
    "            ).execute()\n",
    "            \n",
    "            items = response.get('files', [])\n",
    "            if not items:\n",
    "                self._log_message(f\"Nenhum arquivo encontrado na pasta '{folder_name}'.\")\n",
    "                return None\n",
    "\n",
    "            file_to_download = items[0]\n",
    "            file_id = file_to_download['id']\n",
    "            file_name = file_to_download['name']\n",
    "            \n",
    "            self._download_file_from_drive(file_id, file_name, local_path)\n",
    "            self._delete_file_from_drive(file_id, file_name)\n",
    "            \n",
    "            return file_name\n",
    "        except Exception as e:\n",
    "            self._log_error(f\"Erro durante o processo de download local: {e}\")\n",
    "\n",
    "    def delete_local_file(self, file_name, local_path=\"downloads\"):\n",
    "        \"\"\"\n",
    "        Remove um arquivo do diretório de download local.\n",
    "\n",
    "        Args:\n",
    "            file_name (str): O nome do arquivo a ser removido.\n",
    "            local_path (str): O caminho para o diretório local.\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(local_path, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            self._log_message(f\"Arquivo '{file_name}' removido do diretório local '{local_path}'.\")\n",
    "        else:\n",
    "            self._log_message(f\"Arquivo '{file_name}' não encontrado em '{local_path}'. Nenhuma ação necessária.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b236894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manager = manager_img_gee('ee-raullomonte13-ic')\n",
    "# path = 'data/CV_shp/campo_verde.shp'\n",
    "# gdf_cv = gpd.read_file(path)\n",
    "\n",
    "# geometry = gdf_cv.geometry.values[0]  # Extrai o polígono como objeto shapely\n",
    "\n",
    "# geo_json = geometry.__geo_interface__\n",
    "# polygon_ee = ee.Geometry.Polygon(geo_json['coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc95d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = manager_img_gee('ee-raullomonte13-ic')\n",
    "path = '../msn/PL_data/MT_Municipios_2024/MT_Municipios_2024.shp'\n",
    "gdf = gpd.read_file(path)\n",
    "gdf = gdf[gdf['NM_MUN'] == 'Primavera do Leste']\n",
    "gdf.to_file('../msn/PL_data/PL_shp/PL_shp.shp')\n",
    "geometry = gdf.geometry.values[0]  # Extrai o polígono como objeto shapely\n",
    "\n",
    "geo_json = geometry.__geo_interface__\n",
    "polygon_ee = ee.Geometry.Polygon(geo_json['coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41264d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-28 09:16:08] - Usando datas específicas fornecidas: ['2015-11-10', '2015-12-16']\n",
      "[2025-10-28 09:16:08] - Verificando disponibilidade de imagens Sentinel-1 para todas as datas especificadas...\n",
      "[2025-10-28 09:16:13] - Todas as datas possuem imagens disponíveis. Iniciando exportação...\n",
      "[2025-10-28 09:16:19] - Verificando a pasta 'PL_Sentinel1_v3' no Google Drive...\n",
      "[2025-10-28 09:16:19] - Pasta 'PL_Sentinel1_v3' verificada com sucesso.\n",
      "[2025-10-28 09:16:23] - Tarefa de exportação iniciada: PL_sentinel1_sentinel1_2015-11-10_img01\n",
      "[2025-10-28 09:16:32] - Tarefa de exportação iniciada: PL_sentinel1_sentinel1_2015-12-16_img01\n",
      "[2025-10-28 09:16:36] - Tarefa de exportação iniciada: PL_sentinel1_sentinel1_2015-12-16_img02\n"
     ]
    }
   ],
   "source": [
    "manager = manager_img_gee('ee-raullomonte13-ic')\n",
    "\n",
    "datas = ['2015-11-10','2015-12-16']\n",
    "manager.export_images_to_drive(area_of_interest=polygon_ee,\n",
    "                           start_date='2015-10-25',\n",
    "                           end_date='2016-07-15',\n",
    "                           satellite='sentinel1',\n",
    "                           folder_name='PL_Sentinel1_v3',\n",
    "                           base_filename='PL_sentinel1',\n",
    "                            sentinel1_dates=datas\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b3a6a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d8d0eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_base_filename_sem_SR_sentinel2_2022-08-02_2023-10-31.tif'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f980349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-10 17:31:04] - Arquivo 'test_base_filename_sem_SR_sentinel2_2022-08-02_2023-10-31.tif' removido do diretório local 'downloads'.\n"
     ]
    }
   ],
   "source": [
    "manager.get_delete_local(file_name=file_name, local_path='downloads')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
